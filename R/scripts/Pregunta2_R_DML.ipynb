{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f42c4f-7165-4865-b1bc-a828358e3d46",
   "metadata": {},
   "source": [
    "# **Set-up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7baccb39-3695-41a8-8174-5eeb6e8ce6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'xtable' is in use and will not be installed\"\n",
      "Warning message:\n",
      "\"package 'hdm' is in use and will not be installed\"\n",
      "Warning message:\n",
      "\"package 'randomForest' is in use and will not be installed\"\n",
      "Warning message:\n",
      "\"package 'glmnet' is in use and will not be installed\"\n",
      "Warning message:\n",
      "\"package 'sandwich' is in use and will not be installed\"\n",
      "Warning message:\n",
      "\"package 'nnet' is in use and will not be installed\"\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"xtable\")\n",
    "install.packages(\"hdm\")\n",
    "install.packages(\"randomForest\")\n",
    "install.packages(\"glmnet\")\n",
    "install.packages(\"sandwich\")\n",
    "install.packages(\"nnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1295dec0-87ed-420f-af35-68421bf6920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xtable)\n",
    "library(randomForest)\n",
    "library(hdm)\n",
    "library(glmnet)\n",
    "library(sandwich)\n",
    "library(nnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2934d-681a-4f1a-ae3e-988fab597d2a",
   "metadata": {},
   "source": [
    "# **I. Cleaning and Set-Up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e42df23-ad09-49ca-bf11-5f73f2095455",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e244baf-af45-4ade-a6d5-ded2b888e080",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5099 × 28</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>abdt</th><th scope=col>tg</th><th scope=col>inuidur1</th><th scope=col>inuidur2</th><th scope=col>female</th><th scope=col>black</th><th scope=col>hispanic</th><th scope=col>othrace</th><th scope=col>dep</th><th scope=col>q1</th><th scope=col>⋯</th><th scope=col>durable</th><th scope=col>nondurable</th><th scope=col>lusd</th><th scope=col>husd</th><th scope=col>muld</th><th scope=col>T4</th><th scope=col>log_inuidur1</th><th scope=col>dep_0</th><th scope=col>dep_1</th><th scope=col>dep_2</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>⋯</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>10824</td><td>0</td><td>18</td><td>18</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>2.890372</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>10824</td><td>0</td><td> 1</td><td> 1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0.000000</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>10747</td><td>0</td><td>27</td><td>27</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3.295837</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>10607</td><td>4</td><td> 9</td><td> 9</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>2.197225</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>10831</td><td>0</td><td>27</td><td>27</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3.295837</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>10845</td><td>0</td><td>27</td><td>27</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3.295837</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>10831</td><td>0</td><td> 9</td><td> 9</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2.197225</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>10859</td><td>0</td><td>27</td><td>27</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3.295837</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>23</th><td>10516</td><td>0</td><td>15</td><td>15</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2.708050</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>25</th><td>10663</td><td>0</td><td>28</td><td>11</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3.332205</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>26</th><td>10747</td><td>0</td><td>12</td><td>12</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2.484907</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>27</th><td>10551</td><td>4</td><td>22</td><td>22</td><td>1</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>3.091042</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>32</th><td>10768</td><td>0</td><td>18</td><td>18</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2.890372</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>33</th><td>10537</td><td>0</td><td> 1</td><td> 1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0.000000</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>39</th><td>10600</td><td>4</td><td> 7</td><td> 7</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1.945910</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>43</th><td>10866</td><td>0</td><td>18</td><td>18</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2.890372</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>49</th><td>10572</td><td>0</td><td>14</td><td>14</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2.639057</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>50</th><td>10663</td><td>0</td><td> 5</td><td> 5</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1.609438</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>58</th><td>10789</td><td>0</td><td> 9</td><td> 9</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2.197225</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>59</th><td>10768</td><td>0</td><td> 3</td><td> 3</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1.098612</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>60</th><td>10649</td><td>0</td><td>27</td><td>27</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>3.295837</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>61</th><td>10670</td><td>4</td><td>27</td><td>27</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>3.295837</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>63</th><td>10796</td><td>0</td><td>10</td><td>10</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>2.302585</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>65</th><td>10558</td><td>0</td><td>25</td><td>25</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3.218876</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>72</th><td>10831</td><td>4</td><td> 1</td><td> 1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0.000000</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>73</th><td>10810</td><td>4</td><td> 3</td><td> 3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1.098612</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>75</th><td>10551</td><td>4</td><td>13</td><td>13</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>2.564949</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>77</th><td>10796</td><td>0</td><td> 1</td><td> 1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0.000000</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>81</th><td>10719</td><td>0</td><td>27</td><td>27</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3.295837</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>82</th><td>10726</td><td>4</td><td>14</td><td>14</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>2.639057</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><th scope=row>13829</th><td>10558</td><td>0</td><td>20</td><td>20</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2.9957323</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13831</th><td>10852</td><td>4</td><td>27</td><td>27</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>3.2958369</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13842</th><td>10579</td><td>4</td><td>13</td><td>13</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>2.5649494</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13845</th><td>10796</td><td>0</td><td> 1</td><td> 1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>⋯</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0.0000000</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13846</th><td>10782</td><td>0</td><td> 1</td><td> 1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0.0000000</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13847</th><td>10579</td><td>4</td><td>16</td><td>16</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>2.7725887</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>13854</th><td>10544</td><td>0</td><td>13</td><td>13</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2.5649494</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13864</th><td>10628</td><td>0</td><td>10</td><td>10</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2.3025851</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13872</th><td>10593</td><td>4</td><td> 1</td><td> 1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0.0000000</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13873</th><td>10593</td><td>4</td><td> 2</td><td> 2</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0.6931472</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>13875</th><td>10712</td><td>0</td><td>22</td><td>22</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>3.0910425</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>13876</th><td>10768</td><td>0</td><td>27</td><td>27</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>3.2958369</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13877</th><td>10817</td><td>0</td><td>16</td><td>16</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2.7725887</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13880</th><td>10572</td><td>4</td><td>17</td><td>17</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>2.8332133</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>13883</th><td>10845</td><td>4</td><td> 2</td><td> 2</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>⋯</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0.6931472</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13888</th><td>10642</td><td>0</td><td>10</td><td>10</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2.3025851</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13891</th><td>10670</td><td>0</td><td>20</td><td>20</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>2.9957323</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13892</th><td>10530</td><td>0</td><td>27</td><td>27</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>3.2958369</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13893</th><td>10691</td><td>0</td><td>27</td><td>27</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3.2958369</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13894</th><td>10796</td><td>0</td><td>15</td><td>15</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2.7080502</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13895</th><td>10635</td><td>4</td><td>20</td><td>20</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>2.9957323</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13896</th><td>10859</td><td>0</td><td> 1</td><td> 1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0.0000000</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13899</th><td>10796</td><td>0</td><td>23</td><td>23</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>3.1354942</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13900</th><td>10740</td><td>4</td><td>13</td><td>13</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>2.5649494</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13901</th><td>10845</td><td>0</td><td> 6</td><td> 6</td><td>1</td><td>0</td><td>0</td><td>1</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1.7917595</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>13905</th><td>10628</td><td>4</td><td>10</td><td>10</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>2.3025851</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13906</th><td>10523</td><td>4</td><td> 4</td><td> 4</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1.3862944</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>13907</th><td>10558</td><td>0</td><td> 9</td><td> 9</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2.1972246</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>13911</th><td>10817</td><td>4</td><td> 4</td><td> 4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1.3862944</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>13912</th><td>10691</td><td>0</td><td>27</td><td>27</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3.2958369</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5099 × 28\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & abdt & tg & inuidur1 & inuidur2 & female & black & hispanic & othrace & dep & q1 & ⋯ & durable & nondurable & lusd & husd & muld & T4 & log\\_inuidur1 & dep\\_0 & dep\\_1 & dep\\_2\\\\\n",
       "  & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & ⋯ & <int> & <int> & <int> & <int> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 10824 & 0 & 18 & 18 & 0 & 0 & 0 & 0 & 2 & 0 & ⋯ & 0 & 0 & 0 & 1 & 0 & 0 & 2.890372 & 0 & 0 & 1\\\\\n",
       "\t4 & 10824 & 0 &  1 &  1 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 0.000000 & 1 & 0 & 0\\\\\n",
       "\t5 & 10747 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 3.295837 & 1 & 0 & 0\\\\\n",
       "\t12 & 10607 & 4 &  9 &  9 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 1 & 2.197225 & 1 & 0 & 0\\\\\n",
       "\t13 & 10831 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 1 & 0 & ⋯ & 1 & 0 & 1 & 0 & 0 & 0 & 3.295837 & 0 & 1 & 0\\\\\n",
       "\t14 & 10845 & 0 & 27 & 27 & 1 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 3.295837 & 1 & 0 & 0\\\\\n",
       "\t15 & 10831 & 0 &  9 &  9 & 1 & 0 & 0 & 0 & 1 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 2.197225 & 0 & 1 & 0\\\\\n",
       "\t17 & 10859 & 0 & 27 & 27 & 1 & 0 & 0 & 0 & 1 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 3.295837 & 0 & 1 & 0\\\\\n",
       "\t23 & 10516 & 0 & 15 & 15 & 1 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 2.708050 & 1 & 0 & 0\\\\\n",
       "\t25 & 10663 & 0 & 28 & 11 & 1 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 3.332205 & 1 & 0 & 0\\\\\n",
       "\t26 & 10747 & 0 & 12 & 12 & 1 & 0 & 0 & 0 & 2 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 0 & 2.484907 & 0 & 0 & 1\\\\\n",
       "\t27 & 10551 & 4 & 22 & 22 & 1 & 0 & 1 & 0 & 2 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 1 & 3.091042 & 0 & 0 & 1\\\\\n",
       "\t32 & 10768 & 0 & 18 & 18 & 1 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 0 & 2.890372 & 1 & 0 & 0\\\\\n",
       "\t33 & 10537 & 0 &  1 &  1 & 1 & 0 & 0 & 0 & 2 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 0 & 0.000000 & 0 & 0 & 1\\\\\n",
       "\t39 & 10600 & 4 &  7 &  7 & 1 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 1 & 1.945910 & 1 & 0 & 0\\\\\n",
       "\t43 & 10866 & 0 & 18 & 18 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 1 & 0 & 1 & 0 & 0 & 0 & 2.890372 & 1 & 0 & 0\\\\\n",
       "\t49 & 10572 & 0 & 14 & 14 & 0 & 0 & 0 & 0 & 2 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 2.639057 & 0 & 0 & 1\\\\\n",
       "\t50 & 10663 & 0 &  5 &  5 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 1.609438 & 1 & 0 & 0\\\\\n",
       "\t58 & 10789 & 0 &  9 &  9 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 1 & 1 & 0 & 0 & 0 & 2.197225 & 1 & 0 & 0\\\\\n",
       "\t59 & 10768 & 0 &  3 &  3 & 0 & 1 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 0 & 1.098612 & 1 & 0 & 0\\\\\n",
       "\t60 & 10649 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 1 & 0 & ⋯ & 0 & 0 & 0 & 1 & 0 & 0 & 3.295837 & 0 & 1 & 0\\\\\n",
       "\t61 & 10670 & 4 & 27 & 27 & 1 & 0 & 0 & 0 & 2 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 1 & 3.295837 & 0 & 0 & 1\\\\\n",
       "\t63 & 10796 & 0 & 10 & 10 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 1 & 0 & 0 & 2.302585 & 1 & 0 & 0\\\\\n",
       "\t65 & 10558 & 0 & 25 & 25 & 0 & 0 & 1 & 0 & 2 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 3.218876 & 0 & 0 & 1\\\\\n",
       "\t72 & 10831 & 4 &  1 &  1 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 1 & 0.000000 & 1 & 0 & 0\\\\\n",
       "\t73 & 10810 & 4 &  3 &  3 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 1 & 0 & 1 & 1.098612 & 1 & 0 & 0\\\\\n",
       "\t75 & 10551 & 4 & 13 & 13 & 0 & 0 & 0 & 0 & 2 & 0 & ⋯ & 0 & 0 & 0 & 1 & 0 & 1 & 2.564949 & 0 & 0 & 1\\\\\n",
       "\t77 & 10796 & 0 &  1 &  1 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 1 & 0 & 0 & 0.000000 & 1 & 0 & 0\\\\\n",
       "\t81 & 10719 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 1 & 0 & 1 & 0 & 0 & 0 & 3.295837 & 1 & 0 & 0\\\\\n",
       "\t82 & 10726 & 4 & 14 & 14 & 0 & 0 & 0 & 0 & 2 & 0 & ⋯ & 0 & 1 & 1 & 0 & 0 & 1 & 2.639057 & 0 & 0 & 1\\\\\n",
       "\t⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t13829 & 10558 & 0 & 20 & 20 & 0 & 0 & 1 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 0 & 2.9957323 & 1 & 0 & 0\\\\\n",
       "\t13831 & 10852 & 4 & 27 & 27 & 0 & 0 & 1 & 0 & 0 & 0 & ⋯ & 1 & 0 & 0 & 0 & 1 & 1 & 3.2958369 & 1 & 0 & 0\\\\\n",
       "\t13842 & 10579 & 4 & 13 & 13 & 0 & 0 & 1 & 0 & 1 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 1 & 2.5649494 & 0 & 1 & 0\\\\\n",
       "\t13845 & 10796 & 0 &  1 &  1 & 1 & 0 & 1 & 0 & 1 & 0 & ⋯ & 0 & 1 & 1 & 0 & 0 & 0 & 0.0000000 & 0 & 1 & 0\\\\\n",
       "\t13846 & 10782 & 0 &  1 &  1 & 0 & 0 & 1 & 0 & 1 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 0.0000000 & 0 & 1 & 0\\\\\n",
       "\t13847 & 10579 & 4 & 16 & 16 & 0 & 0 & 1 & 0 & 2 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 1 & 2.7725887 & 0 & 0 & 1\\\\\n",
       "\t13854 & 10544 & 0 & 13 & 13 & 0 & 0 & 1 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 0 & 2.5649494 & 1 & 0 & 0\\\\\n",
       "\t13864 & 10628 & 0 & 10 & 10 & 0 & 0 & 1 & 0 & 0 & 0 & ⋯ & 1 & 0 & 0 & 0 & 1 & 0 & 2.3025851 & 1 & 0 & 0\\\\\n",
       "\t13872 & 10593 & 4 &  1 &  1 & 0 & 0 & 1 & 0 & 0 & 0 & ⋯ & 0 & 1 & 1 & 0 & 0 & 1 & 0.0000000 & 1 & 0 & 0\\\\\n",
       "\t13873 & 10593 & 4 &  2 &  2 & 0 & 0 & 1 & 0 & 2 & 0 & ⋯ & 1 & 0 & 1 & 0 & 0 & 1 & 0.6931472 & 0 & 0 & 1\\\\\n",
       "\t13875 & 10712 & 0 & 22 & 22 & 0 & 0 & 1 & 0 & 2 & 0 & ⋯ & 0 & 1 & 0 & 0 & 1 & 0 & 3.0910425 & 0 & 0 & 1\\\\\n",
       "\t13876 & 10768 & 0 & 27 & 27 & 0 & 0 & 1 & 0 & 0 & 0 & ⋯ & 1 & 0 & 0 & 0 & 1 & 0 & 3.2958369 & 1 & 0 & 0\\\\\n",
       "\t13877 & 10817 & 0 & 16 & 16 & 1 & 0 & 1 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 0 & 2.7725887 & 1 & 0 & 0\\\\\n",
       "\t13880 & 10572 & 4 & 17 & 17 & 0 & 0 & 1 & 0 & 2 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 1 & 2.8332133 & 0 & 0 & 1\\\\\n",
       "\t13883 & 10845 & 4 &  2 &  2 & 1 & 0 & 1 & 0 & 1 & 0 & ⋯ & 0 & 1 & 0 & 0 & 1 & 1 & 0.6931472 & 0 & 1 & 0\\\\\n",
       "\t13888 & 10642 & 0 & 10 & 10 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 1 & 0 & 1 & 0 & 0 & 0 & 2.3025851 & 1 & 0 & 0\\\\\n",
       "\t13891 & 10670 & 0 & 20 & 20 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 1 & 0 & 0 & 1 & 0 & 0 & 2.9957323 & 1 & 0 & 0\\\\\n",
       "\t13892 & 10530 & 0 & 27 & 27 & 1 & 0 & 0 & 1 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 0 & 3.2958369 & 1 & 0 & 0\\\\\n",
       "\t13893 & 10691 & 0 & 27 & 27 & 1 & 0 & 0 & 1 & 0 & 0 & ⋯ & 1 & 0 & 1 & 0 & 0 & 0 & 3.2958369 & 1 & 0 & 0\\\\\n",
       "\t13894 & 10796 & 0 & 15 & 15 & 1 & 0 & 0 & 1 & 0 & 0 & ⋯ & 1 & 0 & 1 & 0 & 0 & 0 & 2.7080502 & 1 & 0 & 0\\\\\n",
       "\t13895 & 10635 & 4 & 20 & 20 & 0 & 0 & 0 & 1 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 1 & 2.9957323 & 1 & 0 & 0\\\\\n",
       "\t13896 & 10859 & 0 &  1 &  1 & 1 & 0 & 0 & 1 & 0 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 0.0000000 & 1 & 0 & 0\\\\\n",
       "\t13899 & 10796 & 0 & 23 & 23 & 0 & 1 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 0 & 3.1354942 & 1 & 0 & 0\\\\\n",
       "\t13900 & 10740 & 4 & 13 & 13 & 1 & 1 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 1 & 2.5649494 & 1 & 0 & 0\\\\\n",
       "\t13901 & 10845 & 0 &  6 &  6 & 1 & 0 & 0 & 1 & 2 & 0 & ⋯ & 0 & 1 & 0 & 0 & 1 & 0 & 1.7917595 & 0 & 0 & 1\\\\\n",
       "\t13905 & 10628 & 4 & 10 & 10 & 0 & 0 & 1 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 1 & 2.3025851 & 1 & 0 & 0\\\\\n",
       "\t13906 & 10523 & 4 &  4 &  4 & 0 & 0 & 1 & 0 & 2 & 0 & ⋯ & 0 & 0 & 0 & 0 & 1 & 1 & 1.3862944 & 0 & 0 & 1\\\\\n",
       "\t13907 & 10558 & 0 &  9 &  9 & 0 & 0 & 0 & 0 & 2 & 0 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 2.1972246 & 0 & 0 & 1\\\\\n",
       "\t13911 & 10817 & 4 &  4 &  4 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 0 & 0 & 0 & 0 & 0 & 1 & 1.3862944 & 1 & 0 & 0\\\\\n",
       "\t13912 & 10691 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 1 & 0 & 1 & 0 & 0 & 0 & 3.2958369 & 1 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5099 × 28\n",
       "\n",
       "| <!--/--> | abdt &lt;int&gt; | tg &lt;int&gt; | inuidur1 &lt;int&gt; | inuidur2 &lt;int&gt; | female &lt;int&gt; | black &lt;int&gt; | hispanic &lt;int&gt; | othrace &lt;int&gt; | dep &lt;int&gt; | q1 &lt;int&gt; | ⋯ ⋯ | durable &lt;int&gt; | nondurable &lt;int&gt; | lusd &lt;int&gt; | husd &lt;int&gt; | muld &lt;int&gt; | T4 &lt;dbl&gt; | log_inuidur1 &lt;dbl&gt; | dep_0 &lt;dbl&gt; | dep_1 &lt;dbl&gt; | dep_2 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 10824 | 0 | 18 | 18 | 0 | 0 | 0 | 0 | 2 | 0 | ⋯ | 0 | 0 | 0 | 1 | 0 | 0 | 2.890372 | 0 | 0 | 1 |\n",
       "| 4 | 10824 | 0 |  1 |  1 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 0.000000 | 1 | 0 | 0 |\n",
       "| 5 | 10747 | 0 | 27 | 27 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 3.295837 | 1 | 0 | 0 |\n",
       "| 12 | 10607 | 4 |  9 |  9 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 1 | 2.197225 | 1 | 0 | 0 |\n",
       "| 13 | 10831 | 0 | 27 | 27 | 0 | 0 | 0 | 0 | 1 | 0 | ⋯ | 1 | 0 | 1 | 0 | 0 | 0 | 3.295837 | 0 | 1 | 0 |\n",
       "| 14 | 10845 | 0 | 27 | 27 | 1 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 3.295837 | 1 | 0 | 0 |\n",
       "| 15 | 10831 | 0 |  9 |  9 | 1 | 0 | 0 | 0 | 1 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 2.197225 | 0 | 1 | 0 |\n",
       "| 17 | 10859 | 0 | 27 | 27 | 1 | 0 | 0 | 0 | 1 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 3.295837 | 0 | 1 | 0 |\n",
       "| 23 | 10516 | 0 | 15 | 15 | 1 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 2.708050 | 1 | 0 | 0 |\n",
       "| 25 | 10663 | 0 | 28 | 11 | 1 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 3.332205 | 1 | 0 | 0 |\n",
       "| 26 | 10747 | 0 | 12 | 12 | 1 | 0 | 0 | 0 | 2 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 0 | 2.484907 | 0 | 0 | 1 |\n",
       "| 27 | 10551 | 4 | 22 | 22 | 1 | 0 | 1 | 0 | 2 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 1 | 3.091042 | 0 | 0 | 1 |\n",
       "| 32 | 10768 | 0 | 18 | 18 | 1 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 0 | 2.890372 | 1 | 0 | 0 |\n",
       "| 33 | 10537 | 0 |  1 |  1 | 1 | 0 | 0 | 0 | 2 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 0 | 0.000000 | 0 | 0 | 1 |\n",
       "| 39 | 10600 | 4 |  7 |  7 | 1 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 1 | 1.945910 | 1 | 0 | 0 |\n",
       "| 43 | 10866 | 0 | 18 | 18 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 1 | 0 | 1 | 0 | 0 | 0 | 2.890372 | 1 | 0 | 0 |\n",
       "| 49 | 10572 | 0 | 14 | 14 | 0 | 0 | 0 | 0 | 2 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 2.639057 | 0 | 0 | 1 |\n",
       "| 50 | 10663 | 0 |  5 |  5 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 1.609438 | 1 | 0 | 0 |\n",
       "| 58 | 10789 | 0 |  9 |  9 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 1 | 1 | 0 | 0 | 0 | 2.197225 | 1 | 0 | 0 |\n",
       "| 59 | 10768 | 0 |  3 |  3 | 0 | 1 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 0 | 1.098612 | 1 | 0 | 0 |\n",
       "| 60 | 10649 | 0 | 27 | 27 | 0 | 0 | 0 | 0 | 1 | 0 | ⋯ | 0 | 0 | 0 | 1 | 0 | 0 | 3.295837 | 0 | 1 | 0 |\n",
       "| 61 | 10670 | 4 | 27 | 27 | 1 | 0 | 0 | 0 | 2 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 1 | 3.295837 | 0 | 0 | 1 |\n",
       "| 63 | 10796 | 0 | 10 | 10 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 1 | 0 | 0 | 2.302585 | 1 | 0 | 0 |\n",
       "| 65 | 10558 | 0 | 25 | 25 | 0 | 0 | 1 | 0 | 2 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 3.218876 | 0 | 0 | 1 |\n",
       "| 72 | 10831 | 4 |  1 |  1 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 1 | 0.000000 | 1 | 0 | 0 |\n",
       "| 73 | 10810 | 4 |  3 |  3 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 1 | 0 | 1 | 1.098612 | 1 | 0 | 0 |\n",
       "| 75 | 10551 | 4 | 13 | 13 | 0 | 0 | 0 | 0 | 2 | 0 | ⋯ | 0 | 0 | 0 | 1 | 0 | 1 | 2.564949 | 0 | 0 | 1 |\n",
       "| 77 | 10796 | 0 |  1 |  1 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 1 | 0 | 0 | 0.000000 | 1 | 0 | 0 |\n",
       "| 81 | 10719 | 0 | 27 | 27 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 1 | 0 | 1 | 0 | 0 | 0 | 3.295837 | 1 | 0 | 0 |\n",
       "| 82 | 10726 | 4 | 14 | 14 | 0 | 0 | 0 | 0 | 2 | 0 | ⋯ | 0 | 1 | 1 | 0 | 0 | 1 | 2.639057 | 0 | 0 | 1 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 13829 | 10558 | 0 | 20 | 20 | 0 | 0 | 1 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 0 | 2.9957323 | 1 | 0 | 0 |\n",
       "| 13831 | 10852 | 4 | 27 | 27 | 0 | 0 | 1 | 0 | 0 | 0 | ⋯ | 1 | 0 | 0 | 0 | 1 | 1 | 3.2958369 | 1 | 0 | 0 |\n",
       "| 13842 | 10579 | 4 | 13 | 13 | 0 | 0 | 1 | 0 | 1 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 1 | 2.5649494 | 0 | 1 | 0 |\n",
       "| 13845 | 10796 | 0 |  1 |  1 | 1 | 0 | 1 | 0 | 1 | 0 | ⋯ | 0 | 1 | 1 | 0 | 0 | 0 | 0.0000000 | 0 | 1 | 0 |\n",
       "| 13846 | 10782 | 0 |  1 |  1 | 0 | 0 | 1 | 0 | 1 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 0.0000000 | 0 | 1 | 0 |\n",
       "| 13847 | 10579 | 4 | 16 | 16 | 0 | 0 | 1 | 0 | 2 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 1 | 2.7725887 | 0 | 0 | 1 |\n",
       "| 13854 | 10544 | 0 | 13 | 13 | 0 | 0 | 1 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 0 | 2.5649494 | 1 | 0 | 0 |\n",
       "| 13864 | 10628 | 0 | 10 | 10 | 0 | 0 | 1 | 0 | 0 | 0 | ⋯ | 1 | 0 | 0 | 0 | 1 | 0 | 2.3025851 | 1 | 0 | 0 |\n",
       "| 13872 | 10593 | 4 |  1 |  1 | 0 | 0 | 1 | 0 | 0 | 0 | ⋯ | 0 | 1 | 1 | 0 | 0 | 1 | 0.0000000 | 1 | 0 | 0 |\n",
       "| 13873 | 10593 | 4 |  2 |  2 | 0 | 0 | 1 | 0 | 2 | 0 | ⋯ | 1 | 0 | 1 | 0 | 0 | 1 | 0.6931472 | 0 | 0 | 1 |\n",
       "| 13875 | 10712 | 0 | 22 | 22 | 0 | 0 | 1 | 0 | 2 | 0 | ⋯ | 0 | 1 | 0 | 0 | 1 | 0 | 3.0910425 | 0 | 0 | 1 |\n",
       "| 13876 | 10768 | 0 | 27 | 27 | 0 | 0 | 1 | 0 | 0 | 0 | ⋯ | 1 | 0 | 0 | 0 | 1 | 0 | 3.2958369 | 1 | 0 | 0 |\n",
       "| 13877 | 10817 | 0 | 16 | 16 | 1 | 0 | 1 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 0 | 2.7725887 | 1 | 0 | 0 |\n",
       "| 13880 | 10572 | 4 | 17 | 17 | 0 | 0 | 1 | 0 | 2 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 1 | 2.8332133 | 0 | 0 | 1 |\n",
       "| 13883 | 10845 | 4 |  2 |  2 | 1 | 0 | 1 | 0 | 1 | 0 | ⋯ | 0 | 1 | 0 | 0 | 1 | 1 | 0.6931472 | 0 | 1 | 0 |\n",
       "| 13888 | 10642 | 0 | 10 | 10 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 1 | 0 | 1 | 0 | 0 | 0 | 2.3025851 | 1 | 0 | 0 |\n",
       "| 13891 | 10670 | 0 | 20 | 20 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 1 | 0 | 0 | 1 | 0 | 0 | 2.9957323 | 1 | 0 | 0 |\n",
       "| 13892 | 10530 | 0 | 27 | 27 | 1 | 0 | 0 | 1 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 0 | 3.2958369 | 1 | 0 | 0 |\n",
       "| 13893 | 10691 | 0 | 27 | 27 | 1 | 0 | 0 | 1 | 0 | 0 | ⋯ | 1 | 0 | 1 | 0 | 0 | 0 | 3.2958369 | 1 | 0 | 0 |\n",
       "| 13894 | 10796 | 0 | 15 | 15 | 1 | 0 | 0 | 1 | 0 | 0 | ⋯ | 1 | 0 | 1 | 0 | 0 | 0 | 2.7080502 | 1 | 0 | 0 |\n",
       "| 13895 | 10635 | 4 | 20 | 20 | 0 | 0 | 0 | 1 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 1 | 2.9957323 | 1 | 0 | 0 |\n",
       "| 13896 | 10859 | 0 |  1 |  1 | 1 | 0 | 0 | 1 | 0 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 0.0000000 | 1 | 0 | 0 |\n",
       "| 13899 | 10796 | 0 | 23 | 23 | 0 | 1 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 0 | 3.1354942 | 1 | 0 | 0 |\n",
       "| 13900 | 10740 | 4 | 13 | 13 | 1 | 1 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 1 | 2.5649494 | 1 | 0 | 0 |\n",
       "| 13901 | 10845 | 0 |  6 |  6 | 1 | 0 | 0 | 1 | 2 | 0 | ⋯ | 0 | 1 | 0 | 0 | 1 | 0 | 1.7917595 | 0 | 0 | 1 |\n",
       "| 13905 | 10628 | 4 | 10 | 10 | 0 | 0 | 1 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 1 | 2.3025851 | 1 | 0 | 0 |\n",
       "| 13906 | 10523 | 4 |  4 |  4 | 0 | 0 | 1 | 0 | 2 | 0 | ⋯ | 0 | 0 | 0 | 0 | 1 | 1 | 1.3862944 | 0 | 0 | 1 |\n",
       "| 13907 | 10558 | 0 |  9 |  9 | 0 | 0 | 0 | 0 | 2 | 0 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 2.1972246 | 0 | 0 | 1 |\n",
       "| 13911 | 10817 | 4 |  4 |  4 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 0 | 0 | 0 | 0 | 0 | 1 | 1.3862944 | 1 | 0 | 0 |\n",
       "| 13912 | 10691 | 0 | 27 | 27 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 1 | 0 | 1 | 0 | 0 | 0 | 3.2958369 | 1 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "      abdt  tg inuidur1 inuidur2 female black hispanic othrace dep q1 ⋯ durable\n",
       "1     10824 0  18       18       0      0     0        0       2   0  ⋯ 0      \n",
       "4     10824 0   1        1       0      0     0        0       0   0  ⋯ 0      \n",
       "5     10747 0  27       27       0      0     0        0       0   0  ⋯ 0      \n",
       "12    10607 4   9        9       0      0     0        0       0   0  ⋯ 0      \n",
       "13    10831 0  27       27       0      0     0        0       1   0  ⋯ 1      \n",
       "14    10845 0  27       27       1      0     0        0       0   0  ⋯ 0      \n",
       "15    10831 0   9        9       1      0     0        0       1   0  ⋯ 0      \n",
       "17    10859 0  27       27       1      0     0        0       1   0  ⋯ 0      \n",
       "23    10516 0  15       15       1      0     0        0       0   0  ⋯ 0      \n",
       "25    10663 0  28       11       1      0     0        0       0   0  ⋯ 0      \n",
       "26    10747 0  12       12       1      0     0        0       2   0  ⋯ 0      \n",
       "27    10551 4  22       22       1      0     1        0       2   0  ⋯ 0      \n",
       "32    10768 0  18       18       1      0     0        0       0   0  ⋯ 0      \n",
       "33    10537 0   1        1       1      0     0        0       2   0  ⋯ 0      \n",
       "39    10600 4   7        7       1      0     0        0       0   0  ⋯ 0      \n",
       "43    10866 0  18       18       0      0     0        0       0   0  ⋯ 1      \n",
       "49    10572 0  14       14       0      0     0        0       2   0  ⋯ 0      \n",
       "50    10663 0   5        5       0      0     0        0       0   0  ⋯ 0      \n",
       "58    10789 0   9        9       0      0     0        0       0   0  ⋯ 0      \n",
       "59    10768 0   3        3       0      1     0        0       0   0  ⋯ 0      \n",
       "60    10649 0  27       27       0      0     0        0       1   0  ⋯ 0      \n",
       "61    10670 4  27       27       1      0     0        0       2   0  ⋯ 0      \n",
       "63    10796 0  10       10       0      0     0        0       0   0  ⋯ 0      \n",
       "65    10558 0  25       25       0      0     1        0       2   0  ⋯ 0      \n",
       "72    10831 4   1        1       0      0     0        0       0   0  ⋯ 0      \n",
       "73    10810 4   3        3       0      0     0        0       0   0  ⋯ 0      \n",
       "75    10551 4  13       13       0      0     0        0       2   0  ⋯ 0      \n",
       "77    10796 0   1        1       0      0     0        0       0   0  ⋯ 0      \n",
       "81    10719 0  27       27       0      0     0        0       0   0  ⋯ 1      \n",
       "82    10726 4  14       14       0      0     0        0       2   0  ⋯ 0      \n",
       "⋮     ⋮     ⋮  ⋮        ⋮        ⋮      ⋮     ⋮        ⋮       ⋮   ⋮  ⋱ ⋮      \n",
       "13829 10558 0  20       20       0      0     1        0       0   0  ⋯ 0      \n",
       "13831 10852 4  27       27       0      0     1        0       0   0  ⋯ 1      \n",
       "13842 10579 4  13       13       0      0     1        0       1   0  ⋯ 0      \n",
       "13845 10796 0   1        1       1      0     1        0       1   0  ⋯ 0      \n",
       "13846 10782 0   1        1       0      0     1        0       1   0  ⋯ 0      \n",
       "13847 10579 4  16       16       0      0     1        0       2   0  ⋯ 0      \n",
       "13854 10544 0  13       13       0      0     1        0       0   0  ⋯ 0      \n",
       "13864 10628 0  10       10       0      0     1        0       0   0  ⋯ 1      \n",
       "13872 10593 4   1        1       0      0     1        0       0   0  ⋯ 0      \n",
       "13873 10593 4   2        2       0      0     1        0       2   0  ⋯ 1      \n",
       "13875 10712 0  22       22       0      0     1        0       2   0  ⋯ 0      \n",
       "13876 10768 0  27       27       0      0     1        0       0   0  ⋯ 1      \n",
       "13877 10817 0  16       16       1      0     1        0       0   0  ⋯ 0      \n",
       "13880 10572 4  17       17       0      0     1        0       2   0  ⋯ 0      \n",
       "13883 10845 4   2        2       1      0     1        0       1   0  ⋯ 0      \n",
       "13888 10642 0  10       10       0      0     0        0       0   0  ⋯ 1      \n",
       "13891 10670 0  20       20       0      0     0        0       0   0  ⋯ 1      \n",
       "13892 10530 0  27       27       1      0     0        1       0   0  ⋯ 0      \n",
       "13893 10691 0  27       27       1      0     0        1       0   0  ⋯ 1      \n",
       "13894 10796 0  15       15       1      0     0        1       0   0  ⋯ 1      \n",
       "13895 10635 4  20       20       0      0     0        1       0   0  ⋯ 0      \n",
       "13896 10859 0   1        1       1      0     0        1       0   0  ⋯ 0      \n",
       "13899 10796 0  23       23       0      1     0        0       0   0  ⋯ 0      \n",
       "13900 10740 4  13       13       1      1     0        0       0   0  ⋯ 0      \n",
       "13901 10845 0   6        6       1      0     0        1       2   0  ⋯ 0      \n",
       "13905 10628 4  10       10       0      0     1        0       0   0  ⋯ 0      \n",
       "13906 10523 4   4        4       0      0     1        0       2   0  ⋯ 0      \n",
       "13907 10558 0   9        9       0      0     0        0       2   0  ⋯ 0      \n",
       "13911 10817 4   4        4       0      0     0        0       0   0  ⋯ 0      \n",
       "13912 10691 0  27       27       0      0     0        0       0   0  ⋯ 1      \n",
       "      nondurable lusd husd muld T4 log_inuidur1 dep_0 dep_1 dep_2\n",
       "1     0          0    1    0    0  2.890372     0     0     1    \n",
       "4     0          1    0    0    0  0.000000     1     0     0    \n",
       "5     0          1    0    0    0  3.295837     1     0     0    \n",
       "12    0          0    0    1    1  2.197225     1     0     0    \n",
       "13    0          1    0    0    0  3.295837     0     1     0    \n",
       "14    0          1    0    0    0  3.295837     1     0     0    \n",
       "15    0          1    0    0    0  2.197225     0     1     0    \n",
       "17    0          1    0    0    0  3.295837     0     1     0    \n",
       "23    0          1    0    0    0  2.708050     1     0     0    \n",
       "25    0          1    0    0    0  3.332205     1     0     0    \n",
       "26    0          0    0    1    0  2.484907     0     0     1    \n",
       "27    0          0    0    1    1  3.091042     0     0     1    \n",
       "32    0          0    0    1    0  2.890372     1     0     0    \n",
       "33    0          0    0    1    0  0.000000     0     0     1    \n",
       "39    0          1    0    0    1  1.945910     1     0     0    \n",
       "43    0          1    0    0    0  2.890372     1     0     0    \n",
       "49    0          1    0    0    0  2.639057     0     0     1    \n",
       "50    0          1    0    0    0  1.609438     1     0     0    \n",
       "58    1          1    0    0    0  2.197225     1     0     0    \n",
       "59    0          0    0    1    0  1.098612     1     0     0    \n",
       "60    0          0    1    0    0  3.295837     0     1     0    \n",
       "61    0          0    0    1    1  3.295837     0     0     1    \n",
       "63    0          0    1    0    0  2.302585     1     0     0    \n",
       "65    0          1    0    0    0  3.218876     0     0     1    \n",
       "72    0          1    0    0    1  0.000000     1     0     0    \n",
       "73    0          0    1    0    1  1.098612     1     0     0    \n",
       "75    0          0    1    0    1  2.564949     0     0     1    \n",
       "77    0          0    1    0    0  0.000000     1     0     0    \n",
       "81    0          1    0    0    0  3.295837     1     0     0    \n",
       "82    1          1    0    0    1  2.639057     0     0     1    \n",
       "⋮     ⋮          ⋮    ⋮    ⋮    ⋮  ⋮            ⋮     ⋮     ⋮    \n",
       "13829 0          0    0    1    0  2.9957323    1     0     0    \n",
       "13831 0          0    0    1    1  3.2958369    1     0     0    \n",
       "13842 0          0    0    1    1  2.5649494    0     1     0    \n",
       "13845 1          1    0    0    0  0.0000000    0     1     0    \n",
       "13846 0          1    0    0    0  0.0000000    0     1     0    \n",
       "13847 0          0    0    1    1  2.7725887    0     0     1    \n",
       "13854 0          0    0    1    0  2.5649494    1     0     0    \n",
       "13864 0          0    0    1    0  2.3025851    1     0     0    \n",
       "13872 1          1    0    0    1  0.0000000    1     0     0    \n",
       "13873 0          1    0    0    1  0.6931472    0     0     1    \n",
       "13875 1          0    0    1    0  3.0910425    0     0     1    \n",
       "13876 0          0    0    1    0  3.2958369    1     0     0    \n",
       "13877 0          0    0    1    0  2.7725887    1     0     0    \n",
       "13880 0          0    0    1    1  2.8332133    0     0     1    \n",
       "13883 1          0    0    1    1  0.6931472    0     1     0    \n",
       "13888 0          1    0    0    0  2.3025851    1     0     0    \n",
       "13891 0          0    1    0    0  2.9957323    1     0     0    \n",
       "13892 0          0    0    1    0  3.2958369    1     0     0    \n",
       "13893 0          1    0    0    0  3.2958369    1     0     0    \n",
       "13894 0          1    0    0    0  2.7080502    1     0     0    \n",
       "13895 0          0    0    1    1  2.9957323    1     0     0    \n",
       "13896 0          1    0    0    0  0.0000000    1     0     0    \n",
       "13899 0          0    0    1    0  3.1354942    1     0     0    \n",
       "13900 0          1    0    0    1  2.5649494    1     0     0    \n",
       "13901 1          0    0    1    0  1.7917595    0     0     1    \n",
       "13905 0          0    0    1    1  2.3025851    1     0     0    \n",
       "13906 0          0    0    1    1  1.3862944    0     0     1    \n",
       "13907 0          1    0    0    0  2.1972246    0     0     1    \n",
       "13911 0          0    0    0    1  1.3862944    1     0     0    \n",
       "13912 0          1    0    0    0  3.2958369    1     0     0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data\n",
    "file <- \"https://raw.githubusercontent.com/CausalAIBook/MetricsMLNotebooks/main/data/penn_jae.dat\"\n",
    "data <- read.table(file, header = TRUE)\n",
    "\n",
    "# Mantener solo tg = 0 o 4\n",
    "data <- data[data$tg %in% c(0, 4), ]\n",
    "\n",
    "# Variable de tratamiento\n",
    "data$T4 <- ifelse(data$tg == 4, 1, 0)\n",
    "\n",
    "# Variable de resultado\n",
    "data$log_inuidur1 <- log(data$inuidur1)\n",
    "\n",
    "# Dummies de dep\n",
    "data$dep_0 <- ifelse(data$dep == 0, 1, 0)\n",
    "data$dep_1 <- ifelse(data$dep == 1, 1, 0)\n",
    "data$dep_2 <- ifelse(data$dep == 2, 1, 0)\n",
    "\n",
    "# Definir y, d, x\n",
    "y <- as.matrix(data$log_inuidur1)\n",
    "d <- as.matrix(data$T4)\n",
    "x <- as.matrix(data[, c('female', 'black', 'othrace',\n",
    "                         'dep_1', 'dep_2',\n",
    "                         'q2', 'q3', 'q4', 'q5', 'q6',\n",
    "                         'recall', 'agelt35', 'agegt54',\n",
    "                         'durable', 'nondurable', 'lusd', 'husd')])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da84563-eae5-436d-9243-52199dc12168",
   "metadata": {},
   "source": [
    "# **II. Debiased ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a234b3e-69ce-4f8a-96f9-2e6726984eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DML con OLS\n",
      "fold: 1  2  3  4  5  6  7  8  9  10  \n",
      "coef (se) = -0.0725686 (0.0351348)\n",
      "\n",
      "DML con Lasso\n",
      "fold: 1  2  3  4  5  6  7  8  9  10  \n",
      "coef (se) = -0.0796961 (0.0353666)\n",
      "\n",
      "DML con Random Forest\n",
      "fold: 1  2  3  4  5  6  7  8  9  10  \n",
      "coef (se) = -0.076369 (0.0349711)\n",
      "\n",
      "DML con Neural Network\n",
      "fold: 1  2  3  4  5  6  7  8  9  10  \n",
      "coef (se) = -0.101712 (0.0472255)\n"
     ]
    }
   ],
   "source": [
    "# Función DML\n",
    "DML2.for.PLM <- function(x, d, y, dreg, yreg, nfold=2) {\n",
    "  nobs <- nrow(x)\n",
    "  foldid <- rep.int(1:nfold, times = ceiling(nobs/nfold))[sample.int(nobs)]\n",
    "  I <- split(1:nobs, foldid)\n",
    "  ytil <- dtil <- rep(NA, nobs)\n",
    "  cat(\"fold: \")\n",
    "  for(b in 1:length(I)){\n",
    "    dfit <- dreg(x[-I[[b]],], d[-I[[b]]])\n",
    "    yfit <- yreg(x[-I[[b]],], y[-I[[b]]])\n",
    "    dhat <- predict(dfit, x[I[[b]],], type=\"response\")\n",
    "    yhat <- predict(yfit, x[I[[b]],], type=\"response\")\n",
    "    dtil[I[[b]]] <- (d[I[[b]]] - dhat)\n",
    "    ytil[I[[b]]] <- (y[I[[b]]] - yhat)\n",
    "    cat(b,\" \")\n",
    "  }\n",
    "  rfit <- lm(ytil ~ dtil)\n",
    "  coef.est <- coef(rfit)[2]\n",
    "  se <- sqrt(vcovHC(rfit)[2,2])\n",
    "  cat(sprintf(\"\\ncoef (se) = %g (%g)\\n\", coef.est, se))\n",
    "  return(list(coef.est=coef.est, se=se, dtil=dtil, ytil=ytil))\n",
    "}\n",
    "\n",
    "# DML con OLS\n",
    "cat(sprintf(\"\\nDML con OLS\\n\"))\n",
    "dreg <- function(x,d){ glmnet(x, d, lambda = 0) }\n",
    "yreg <- function(x,y){ glmnet(x, y, lambda = 0) }\n",
    "DML2.OLS = DML2.for.PLM(x, d, y, dreg, yreg, nfold=10)\n",
    "\n",
    "# DML con Lasso\n",
    "cat(sprintf(\"\\nDML con Lasso\\n\"))\n",
    "dreg <- function(x,d){ rlasso(x, d, post=FALSE) }\n",
    "yreg <- function(x,y){ rlasso(x, y, post=FALSE) }\n",
    "DML2.lasso = DML2.for.PLM(x, d, y, dreg, yreg, nfold=10)\n",
    "\n",
    "# DML con Random Forest\n",
    "cat(sprintf(\"\\nDML con Random Forest\\n\"))\n",
    "dreg <- function(x,d){ suppressWarnings(randomForest(x, d)) }\n",
    "yreg <- function(x,y){ suppressWarnings(randomForest(x, y)) }\n",
    "DML2.RF = DML2.for.PLM(x, d, y, dreg, yreg, nfold=10)\n",
    "\n",
    "# DML con Neural Network\n",
    "DML2.for.PLM.NN <- function(x, d, y, dreg, yreg, nfold=2) {\n",
    "  nobs <- nrow(x)\n",
    "  foldid <- rep.int(1:nfold, times = ceiling(nobs/nfold))[sample.int(nobs)]\n",
    "  I <- split(1:nobs, foldid)\n",
    "  ytil <- dtil <- rep(NA, nobs)\n",
    "  cat(\"fold: \")\n",
    "  for(b in 1:length(I)){\n",
    "    dfit <- dreg(x[-I[[b]],], d[-I[[b]]])\n",
    "    yfit <- yreg(x[-I[[b]],], y[-I[[b]]])\n",
    "    dhat <- predict(dfit, x[I[[b]],])\n",
    "    yhat <- predict(yfit, x[I[[b]],])\n",
    "    dtil[I[[b]]] <- (d[I[[b]]] - dhat)\n",
    "    ytil[I[[b]]] <- (y[I[[b]]] - yhat)\n",
    "    cat(b,\" \")\n",
    "  }\n",
    "  rfit <- lm(ytil ~ dtil)\n",
    "  coef.est <- coef(rfit)[2]\n",
    "  se <- sqrt(vcovHC(rfit)[2,2])\n",
    "  cat(sprintf(\"\\ncoef (se) = %g (%g)\\n\", coef.est, se))\n",
    "  return(list(coef.est=coef.est, se=se, dtil=dtil, ytil=ytil))\n",
    "}\n",
    "\n",
    "cat(sprintf(\"\\nDML con Neural Network\\n\"))\n",
    "dreg <- function(x,d){ nnet(x, d, size=5, linout=TRUE, trace=FALSE, maxit=1000) }\n",
    "yreg <- function(x,y){ nnet(x, y, size=5, linout=TRUE, trace=FALSE, maxit=1000) }\n",
    "DML2.NN = DML2.for.PLM.NN(x, d, y, dreg, yreg, nfold=10)\n",
    "\n",
    "# RMSE y Tabla\n",
    "prRes.D <- c(mean((DML2.OLS$dtil)^2), mean((DML2.lasso$dtil)^2), mean((DML2.RF$dtil)^2), mean((DML2.NN$dtil)^2))\n",
    "prRes.Y <- c(mean((DML2.OLS$ytil)^2), mean((DML2.lasso$ytil)^2), mean((DML2.RF$ytil)^2), mean((DML2.NN$ytil)^2))\n",
    "prRes <- rbind(sqrt(prRes.D), sqrt(prRes.Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db245f29-c611-40ec-979c-cf5547b3419d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 4 × 4 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Estimate</th><th scope=col>Standard Error</th><th scope=col>RMSE Y</th><th scope=col>RMSE D</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>OLS</th><td>-0.07256863</td><td>0.03513480</td><td>1.194740</td><td>0.4751677</td></tr>\n",
       "\t<tr><th scope=row>Lasso</th><td>-0.07969611</td><td>0.03536656</td><td>1.198766</td><td>0.4743213</td></tr>\n",
       "\t<tr><th scope=row>RF</th><td>-0.07636905</td><td>0.03497112</td><td>1.206104</td><td>0.4808657</td></tr>\n",
       "\t<tr><th scope=row>Neural Network</th><td>-0.10171178</td><td>0.04722554</td><td>1.437708</td><td>0.4859913</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 4 of type dbl\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Standard Error & RMSE Y & RMSE D\\\\\n",
       "\\hline\n",
       "\tOLS & -0.07256863 & 0.03513480 & 1.194740 & 0.4751677\\\\\n",
       "\tLasso & -0.07969611 & 0.03536656 & 1.198766 & 0.4743213\\\\\n",
       "\tRF & -0.07636905 & 0.03497112 & 1.206104 & 0.4808657\\\\\n",
       "\tNeural Network & -0.10171178 & 0.04722554 & 1.437708 & 0.4859913\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 4 of type dbl\n",
       "\n",
       "| <!--/--> | Estimate | Standard Error | RMSE Y | RMSE D |\n",
       "|---|---|---|---|---|\n",
       "| OLS | -0.07256863 | 0.03513480 | 1.194740 | 0.4751677 |\n",
       "| Lasso | -0.07969611 | 0.03536656 | 1.198766 | 0.4743213 |\n",
       "| RF | -0.07636905 | 0.03497112 | 1.206104 | 0.4808657 |\n",
       "| Neural Network | -0.10171178 | 0.04722554 | 1.437708 | 0.4859913 |\n",
       "\n"
      ],
      "text/plain": [
       "               Estimate    Standard Error RMSE Y   RMSE D   \n",
       "OLS            -0.07256863 0.03513480     1.194740 0.4751677\n",
       "Lasso          -0.07969611 0.03536656     1.198766 0.4743213\n",
       "RF             -0.07636905 0.03497112     1.206104 0.4808657\n",
       "Neural Network -0.10171178 0.04722554     1.437708 0.4859913"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tabla de resultados\n",
    "table <- matrix(0, 4, 4)\n",
    "table[1,1] <- as.numeric(DML2.OLS$coef.est)\n",
    "table[2,1] <- as.numeric(DML2.lasso$coef.est)\n",
    "table[3,1] <- as.numeric(DML2.RF$coef.est)\n",
    "table[4,1] <- as.numeric(DML2.NN$coef.est)\n",
    "\n",
    "table[1,2] <- as.numeric(DML2.OLS$se)\n",
    "table[2,2] <- as.numeric(DML2.lasso$se)\n",
    "table[3,2] <- as.numeric(DML2.RF$se)\n",
    "table[4,2] <- as.numeric(DML2.NN$se)\n",
    "\n",
    "table[1,3] <- as.numeric(prRes[2,1])\n",
    "table[2,3] <- as.numeric(prRes[2,2])\n",
    "table[3,3] <- as.numeric(prRes[2,3])\n",
    "table[4,3] <- as.numeric(prRes[2,4])\n",
    "\n",
    "table[1,4] <- as.numeric(prRes[1,1])\n",
    "table[2,4] <- as.numeric(prRes[1,2])\n",
    "table[3,4] <- as.numeric(prRes[1,3])\n",
    "table[4,4] <- as.numeric(prRes[1,4])\n",
    "\n",
    "colnames(table) <- c(\"Estimate\",\"Standard Error\", \"RMSE Y\", \"RMSE D\")\n",
    "rownames(table) <- c(\"OLS\", \"Lasso\", \"RF\", \"Neural Network\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53b876da-2926-497c-9570-b9ec1565091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Estimate Standard Error RMSE Y RMSE D\n",
      "OLS             -0.0726         0.0351   1.19  0.475\n",
      "Lasso           -0.0797         0.0354   1.20  0.474\n",
      "RF              -0.0764         0.0350   1.21  0.481\n",
      "Neural Network  -0.1017         0.0472   1.44  0.486\n"
     ]
    }
   ],
   "source": [
    "print(table, digit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c81c8bd-4679-4a58-8ee1-2aec6544cdfe",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "Basándome en los resultados, elijo **OLS** y **Lasso** como los modelos más adecuados.  \n",
    "**OLS** tiene el RMSE más bajo para predecir *D* (0.475) y un valor competitivo para *Y* (1.19).  \n",
    "**Lasso** obtiene resultados muy parecidos, con el RMSE D más bajo (0.474) y apenas un poco más alto en *RMSE Y* (1.20).  \n",
    "Además, ambos tienen errores estándar pequeños (~0.035), lo que indica estimaciones bastante precisas.\n",
    "\n",
    "El **Random Forest** muestra RMSE un poco más altos. Además, el **Neural Network** es claramente el peor modelo, pues su *RMSE Y* es de 1.44 (mucho mayor que los demás) y su error estándar es 0.047, casi un 35% más alto que los otros métodos.\n",
    "\n",
    "Por lo tanto, utilizo **OLS y Lasso** para estimar el efecto causal.  \n",
    "Los resultados son muy similares:  \n",
    "- **OLS:** coeficiente = -0.0726 (se = 0.0351)  \n",
    "- **Lasso:** coeficiente = -0.0797 (se = 0.0354)\n",
    "\n",
    "Esto indica que el tratamiento reduce el logaritmo de la duración del desempleo en aproximadamente 0.07–0.08 unidades, un efecto negativo y estadísticamente significativo, consistente entre ambos métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28c89f1-6d1f-4a9a-8e8a-c4dabf325b48",
   "metadata": {},
   "source": [
    "# **III. No cross-fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07a4a1c4-46d3-403b-a1eb-69f632982676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DML sin cross-fitting: OLS\n",
      "\n",
      "coef (se) = -0.0725603 (0.0351333)\n",
      "\n",
      "DML sin cross-fitting: Lasso\n",
      "\n",
      "coef (se) = -0.0791692 (0.0352883)\n",
      "\n",
      "DML sin cross-fitting: Random Forest\n",
      "\n",
      "coef (se) = -0.0759841 (0.035442)\n",
      "\n",
      "DML sin cross-fitting: Neural Network\n",
      "\n",
      "coef (se) = -0.0841915 (0.0361247)\n"
     ]
    }
   ],
   "source": [
    "DML.no.crossfit <- function(x, d, y, dreg, yreg) {\n",
    "  dfit <- dreg(x, d)\n",
    "  yfit <- yreg(x, y)\n",
    "  dhat <- predict(dfit, x, type=\"response\")\n",
    "  yhat <- predict(yfit, x, type=\"response\")\n",
    "  dtil <- d - dhat\n",
    "  ytil <- y - yhat\n",
    "  rfit <- lm(ytil ~ dtil)\n",
    "  coef.est <- coef(rfit)[2]\n",
    "  se <- sqrt(vcovHC(rfit)[2,2])\n",
    "  cat(sprintf(\"\\ncoef (se) = %g (%g)\\n\", coef.est, se))\n",
    "  return(list(coef.est=coef.est, se=se, dtil=dtil, ytil=ytil))\n",
    "}\n",
    "\n",
    "# Función para Neural Network (sin type=\"response\")\n",
    "DML.no.crossfit.NN <- function(x, d, y, dreg, yreg) {\n",
    "  dfit <- dreg(x, d)\n",
    "  yfit <- yreg(x, y)\n",
    "  dhat <- predict(dfit, x)\n",
    "  yhat <- predict(yfit, x)\n",
    "  dtil <- d - dhat\n",
    "  ytil <- y - yhat\n",
    "  rfit <- lm(ytil ~ dtil)\n",
    "  coef.est <- coef(rfit)[2]\n",
    "  se <- sqrt(vcovHC(rfit)[2,2])\n",
    "  cat(sprintf(\"\\ncoef (se) = %g (%g)\\n\", coef.est, se))\n",
    "  return(list(coef.est=coef.est, se=se, dtil=dtil, ytil=ytil))\n",
    "}\n",
    "\n",
    "# OLS\n",
    "cat(sprintf(\"\\nDML sin cross-fitting: OLS\\n\"))\n",
    "dreg <- function(x,d){ glmnet(x, d, lambda = 0) }\n",
    "yreg <- function(x,y){ glmnet(x, y, lambda = 0) }\n",
    "DML.OLS.nocv = DML.no.crossfit(x, d, y, dreg, yreg)\n",
    "\n",
    "# Lasso\n",
    "cat(sprintf(\"\\nDML sin cross-fitting: Lasso\\n\"))\n",
    "dreg <- function(x,d){ rlasso(x, d, post=FALSE) }\n",
    "yreg <- function(x,y){ rlasso(x, y, post=FALSE) }\n",
    "DML.lasso.nocv = DML.no.crossfit(x, d, y, dreg, yreg)\n",
    "\n",
    "# Random Forest\n",
    "cat(sprintf(\"\\nDML sin cross-fitting: Random Forest\\n\"))\n",
    "dreg <- function(x,d){ suppressWarnings(randomForest(x, d)) }\n",
    "yreg <- function(x,y){ suppressWarnings(randomForest(x, y)) }\n",
    "DML.RF.nocv = DML.no.crossfit(x, d, y, dreg, yreg)\n",
    "\n",
    "# Neural Network\n",
    "cat(sprintf(\"\\nDML sin cross-fitting: Neural Network\\n\"))\n",
    "dreg <- function(x,d){ nnet(x, d, size=5, linout=TRUE, trace=FALSE, maxit=1000) }\n",
    "yreg <- function(x,y){ nnet(x, y, size=5, linout=TRUE, trace=FALSE, maxit=1000) }\n",
    "DML.NN.nocv = DML.no.crossfit.NN(x, d, y, dreg, yreg)\n",
    "\n",
    "# RMSE\n",
    "prRes.D.nocv <- c(mean((DML.OLS.nocv$dtil)^2), mean((DML.lasso.nocv$dtil)^2), \n",
    "                   mean((DML.RF.nocv$dtil)^2), mean((DML.NN.nocv$dtil)^2))\n",
    "prRes.Y.nocv <- c(mean((DML.OLS.nocv$ytil)^2), mean((DML.lasso.nocv$ytil)^2), \n",
    "                   mean((DML.RF.nocv$ytil)^2), mean((DML.NN.nocv$ytil)^2))\n",
    "prRes.nocv <- rbind(sqrt(prRes.D.nocv), sqrt(prRes.Y.nocv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc253444-8c47-4a2b-9a44-0e87c0aa0de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Estimate Standard Error RMSE Y RMSE D\n",
      "OLS             -0.0726         0.0351   1.19  0.473\n",
      "Lasso           -0.0792         0.0353   1.20  0.474\n",
      "RF              -0.0760         0.0354   1.12  0.445\n",
      "Neural Network  -0.0842         0.0361   1.21  0.469\n"
     ]
    }
   ],
   "source": [
    "# Tabla\n",
    "table.nocv <- matrix(0, 4, 4)\n",
    "table.nocv[1,1] <- as.numeric(DML.OLS.nocv$coef.est)\n",
    "table.nocv[2,1] <- as.numeric(DML.lasso.nocv$coef.est)\n",
    "table.nocv[3,1] <- as.numeric(DML.RF.nocv$coef.est)\n",
    "table.nocv[4,1] <- as.numeric(DML.NN.nocv$coef.est)\n",
    "\n",
    "table.nocv[1,2] <- as.numeric(DML.OLS.nocv$se)\n",
    "table.nocv[2,2] <- as.numeric(DML.lasso.nocv$se)\n",
    "table.nocv[3,2] <- as.numeric(DML.RF.nocv$se)\n",
    "table.nocv[4,2] <- as.numeric(DML.NN.nocv$se)\n",
    "\n",
    "table.nocv[1,3] <- as.numeric(prRes.nocv[2,1])\n",
    "table.nocv[2,3] <- as.numeric(prRes.nocv[2,2])\n",
    "table.nocv[3,3] <- as.numeric(prRes.nocv[2,3])\n",
    "table.nocv[4,3] <- as.numeric(prRes.nocv[2,4])\n",
    "\n",
    "table.nocv[1,4] <- as.numeric(prRes.nocv[1,1])\n",
    "table.nocv[2,4] <- as.numeric(prRes.nocv[1,2])\n",
    "table.nocv[3,4] <- as.numeric(prRes.nocv[1,3])\n",
    "table.nocv[4,4] <- as.numeric(prRes.nocv[1,4])\n",
    "\n",
    "colnames(table.nocv) <- c(\"Estimate\",\"Standard Error\", \"RMSE Y\", \"RMSE D\")\n",
    "rownames(table.nocv) <- c(\"OLS\", \"Lasso\", \"RF\", \"Neural Network\")\n",
    "\n",
    "print(table.nocv, digits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949665fb-745a-4a10-8931-d776315ad1b0",
   "metadata": {},
   "source": [
    "## Modelo (Sin Cross-Fitting)\n",
    "\n",
    "Basándome en los resultados sin cross-fitting, elijo **Random Forest** como el modelo más adecuado.  \n",
    "**Random Forest** presenta el RMSE más bajo tanto para predecir *Y* (1.12) como para *D* (0.445), superando a los demás métodos.  \n",
    "Su error estándar (0.0354) es muy similar al de **OLS** y **Lasso**, lo que indica una estimación precisa y estable.\n",
    "\n",
    "**OLS** y **Lasso** también muestran buenos resultados, con valores de *RMSE Y* entre 1.19 y 1.20, y *RMSE D* alrededor de 0.47, pero su desempeño es ligeramente inferior al de **Random Forest**.  \n",
    "El **Neural Network** tiene el *RMSE Y* más alto (1.21) y un error estándar un poco mayor (0.0361), aunque su *RMSE D* (0.469) es competitivo.\n",
    "\n",
    "Por lo tanto, utilizo **Random Forest** para estimar el efecto causal sin cross-fitting.  \n",
    "El resultado obtenido es:  \n",
    "- **Random Forest:** coeficiente = -0.0760 (se = 0.0354)\n",
    "\n",
    "Esto indica que el tratamiento reduce el logaritmo de la duración del desempleo en aproximadamente 0.076 unidades, un efecto negativo y estadísticamente significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b7684d-e649-4734-9272-c186f227c3a5",
   "metadata": {},
   "source": [
    "## Comparación: Con vs. Sin Cross-Fitting\n",
    "\n",
    "### 1. ¿Qué puedo decir sobre el RMSE para predecir *y* y *d*?\n",
    "Los RMSE sin cross-fitting son más bajos, sobre todo en los modelos más flexibles.  \n",
    "Por ejemplo:\n",
    "- **Random Forest:** el RMSE de *Y* baja de **1.21** a **1.12** y el de *D* de **0.481** a **0.445**.  \n",
    "- **Neural Network:** el RMSE de *Y* disminuye de **1.44** a **1.21**, y el de *D* de **0.486** a **0.469**.  \n",
    "- En **OLS** y **Lasso**, los cambios son mínimos, prácticamente iguales entre ambos métodos.\n",
    "\n",
    "En general, los modelos más complejos (RF y NN) muestran las reducciones más grandes, mientras que los lineales se mantienen estables.\n",
    "\n",
    "### 2. ¿Por qué una función da RMSE menor que la otra?\n",
    "Los RMSE son menores sin cross-fitting porque hay **sobreajuste (overfitting)**.  \n",
    "En ese caso, el modelo se entrena y se evalúa sobre los mismos datos, por lo que termina “aprendiéndose” el ruido del conjunto de entrenamiento.  \n",
    "Esto hace que los errores parezcan más pequeños, pero en realidad el modelo no está generalizando bien.\n",
    "\n",
    "Los métodos más flexibles, como **Random Forest** y **Neural Network**, tienen más capacidad para ajustarse a los datos, por eso muestran las mayores caídas en RMSE.  \n",
    "Con **cross-fitting**, los modelos predicen sobre datos que no vieron durante el entrenamiento, así que los RMSE son más altos, pero **más realistas y confiables**.\n",
    "\n",
    "### 3. ¿Qué problema hay si estimamos sin cross-fitting?\n",
    "El problema principal es que **las estimaciones del efecto causal se sesgan**.  \n",
    "Sin cross-fitting, los residuales están correlacionados con las predicciones porque se usan los mismos datos para entrenar y estimar.  \n",
    "Esto hace que el coeficiente del tratamiento no sea totalmente confiable y que los errores estándar estén mal calculados.\n",
    "\n",
    "En cambio, **el cross-fitting evita ese sesgo** al usar muestras distintas para entrenar y para predecir, garantizando que los residuales sean independientes.  \n",
    "Así, los resultados son más válidos para inferencia causal y podemos usar modelos flexibles sin perder rigor estadístico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b3583c-ef24-4f01-acfa-ad0afdca79a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
